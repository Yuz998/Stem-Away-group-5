{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/titipata/pubmed_parser.git\n",
      "  Cloning git://github.com/titipata/pubmed_parser.git to /private/var/folders/vl/b2t9x4j11s73llszkqpqlst80000gn/T/pip-req-build-dze9zegc\n",
      "  Running command git clone -q git://github.com/titipata/pubmed_parser.git /private/var/folders/vl/b2t9x4j11s73llszkqpqlst80000gn/T/pip-req-build-dze9zegc\n",
      "Requirement already satisfied (use --upgrade to upgrade): pubmed-parser==0.2.2 from git+git://github.com/titipata/pubmed_parser.git in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages\n",
      "Requirement already satisfied: lxml in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pubmed-parser==0.2.2) (4.5.0)\n",
      "Requirement already satisfied: unidecode in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pubmed-parser==0.2.2) (1.2.0)\n",
      "Requirement already satisfied: requests in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pubmed-parser==0.2.2) (2.22.0)\n",
      "Requirement already satisfied: six in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pubmed-parser==0.2.2) (1.14.0)\n",
      "Requirement already satisfied: numpy in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pubmed-parser==0.2.2) (1.18.1)\n",
      "Requirement already satisfied: pytest in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pubmed-parser==0.2.2) (5.3.5)\n",
      "Requirement already satisfied: pytest-cov in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pubmed-parser==0.2.2) (2.12.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from requests->pubmed-parser==0.2.2) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from requests->pubmed-parser==0.2.2) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from requests->pubmed-parser==0.2.2) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from requests->pubmed-parser==0.2.2) (3.0.4)\n",
      "Requirement already satisfied: py>=1.5.0 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest->pubmed-parser==0.2.2) (1.8.1)\n",
      "Requirement already satisfied: packaging in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest->pubmed-parser==0.2.2) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest->pubmed-parser==0.2.2) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest->pubmed-parser==0.2.2) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest->pubmed-parser==0.2.2) (0.13.1)\n",
      "Requirement already satisfied: wcwidth in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest->pubmed-parser==0.2.2) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest->pubmed-parser==0.2.2) (1.5.0)\n",
      "Requirement already satisfied: toml in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest-cov->pubmed-parser==0.2.2) (0.10.2)\n",
      "Requirement already satisfied: coverage>=5.2.1 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from pytest-cov->pubmed-parser==0.2.2) (5.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from packaging->pytest->pubmed-parser==0.2.2) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/fufu/opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->pubmed-parser==0.2.2) (2.2.0)\n",
      "Building wheels for collected packages: pubmed-parser\n",
      "  Building wheel for pubmed-parser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pubmed-parser: filename=pubmed_parser-0.2.2-py3-none-any.whl size=18318 sha256=c7d9b12fdb6266a65933598673d7c46412ac353a6ab4e70b7da6487cdd5a481c\n",
      "  Stored in directory: /private/var/folders/vl/b2t9x4j11s73llszkqpqlst80000gn/T/pip-ephem-wheel-cache-_s48lbby/wheels/d5/65/90/b0620ddce4e089c02c4468f2a0eb7e482ba7b2f321247857b8\n",
      "Successfully built pubmed-parser\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+git://github.com/titipata/pubmed_parser.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/fufu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yoinked\n",
      "decompressed\n",
      "parsed\n",
      "appended\n",
      "yoinked\n",
      "decompressed\n",
      "parsed\n",
      "appended\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pubmed_parser as pp\n",
    "import pandas as pd\n",
    "from gzip import decompress\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "SIZE = 2 # how many files are we bothering with\n",
    "parsed_files = []\n",
    "fnames = [\"pubmed21n\" + str(num).zfill(4) + \".xml\" for num in range(1,1 + SIZE)]\n",
    "#%% getting + processing files\n",
    "ftp_url = \"https://ftp.ncbi.nlm.nih.gov/pubmed/baseline/\"\n",
    "for fname in fnames:\n",
    "    r = requests.get(ftp_url + fname + '.gz')\n",
    "    print('yoinked')\n",
    "    data = decompress(r.content)\n",
    "    print('decompressed')\n",
    "    medline_data = pd.DataFrame.from_dict(pp.parse_medline_xml(data))\n",
    "    print('parsed')\n",
    "    medline_data = medline_data[['abstract', 'pubdate']]\n",
    "    parsed_files.append(medline_data)\n",
    "    print('appended')\n",
    "\n",
    "#%% create dataframe of parsed files\n",
    "pubmed_df = pd.concat(parsed_files, ignore_index=True)\n",
    "#%% isolate sentences\n",
    "#pull abstracts <= 2015\n",
    "abstracts = [pubmed_df['abstract'][i] for i in pubmed_df.index if int(pubmed_df['pubdate'][i]) <= 2015]\n",
    "sentences = []\n",
    "for abstract in abstracts:\n",
    "    sentences += nltk.tokenize.sent_tokenize(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = []\n",
    "genes = []\n",
    "\n",
    "df_drug = pd.read_csv('./drugs/drugs.tsv', sep='\\t')\n",
    "df_genes = pd.read_csv('./genes/genes.tsv', sep='\\t')\n",
    "\n",
    "drugs.extend(df_drug[\"Name\"])\n",
    "genes.extend(df_genes[\"Name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% narrow sentences down to only those with drug-gene relationships\n",
    "usable_sentences = []\n",
    "set_drugs = set(drugs)\n",
    "set_genes = set(genes)\n",
    "\n",
    "\n",
    "for sentence in sentences:\n",
    "    drug, gene = False, False\n",
    "    token_sentence = nltk.tokenize.word_tokenize(sentence)\n",
    "    for token in token_sentence:\n",
    "        if token in set_drugs:\n",
    "            drug = True\n",
    "        elif token in set_gene:\n",
    "            gene = True\n",
    "        if drug and gene:\n",
    "            usable_sentences.append(sentence)\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_biomedical_sentences = list(set(usable_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to csv file \n",
    "import csv\n",
    "\n",
    "iterable_data = [[sentence] for sentence in all_unique_biomedical_sentences]  \n",
    "# data to be written row-wise in csv fil\n",
    "\"\"\"\n",
    "for sentence in all_unique_biomedical_sentences:\n",
    "    iterable_data.append([sentence])\n",
    "\"\"\"\n",
    "\n",
    "# opening the csv file in 'w+' mode\n",
    "file = open('biomedical sentences.csv', 'w+', newline ='')\n",
    "  \n",
    "# writing the data into the file\n",
    "with file:    \n",
    "    write = csv.writer(file)\n",
    "    write.writerows(iterable_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}